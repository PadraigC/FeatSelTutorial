{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection using Filters\n",
    "### Feature Scoring - two methods  \n",
    "1. Chi square statistic\n",
    "2. Information Gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import chi2, mutual_info_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_data = pd.read_csv('segmentation-all.csv')\n",
    "print(seg_data.shape)\n",
    "seg_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_data['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data, scale it and divide into train and test sets.  \n",
    "The filters are *trained* using the training data and then a classifier is trained on the feature subset and tested on the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = seg_data.pop('Class').values\n",
    "X_raw = seg_data.values\n",
    "\n",
    "X_tr_raw, X_ts_raw, y_train, y_test = train_test_split(X_raw, y, \n",
    "                                                       random_state=1, test_size=1/2)\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_tr_raw)\n",
    "X_test = scaler.transform(X_ts_raw)\n",
    "\n",
    "feature_names = seg_data.columns\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scores  \n",
    "Determine the chi-squared and information gain scores for all features using the training set.   \n",
    "**Note:** The mutual information score returned by `mutual_info_classif` is effectively an information gain score.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2_score, pval = chi2(X_train, y_train)\n",
    "chi2_score = np.nan_to_num(chi2_score)\n",
    "chi2_score\n",
    "# The chi square scores for the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_scores = mutual_info_classif(X_train,y_train)\n",
    "i_scores\n",
    "# The i-gain scores for the features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store the scores in a dataframe indexed by the feature names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({'Mutual Info.':i_scores,'Chi Square':chi2_score,'Feature':feature_names})\n",
    "df.set_index('Feature', inplace = True)\n",
    "df.sort_values('Mutual Info.', inplace = True, ascending = False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the Filter scores\n",
    "We see that the two scores are fairly well correlated.  \n",
    "The Spearman correlation is 0.89."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "rr = range(0,len(feature_names))\n",
    "ax2 = ax.twinx()\n",
    "ax.plot(df.index, df[\"Mutual Info.\"], label='I-Gain')\n",
    "ax2.plot(df.index, df[\"Chi Square\"], color='skyblue', label='Chi Squared')\n",
    "ax.set_xticks(rr)\n",
    "\n",
    "ax.set_xticklabels(list(df.index), rotation = 90)\n",
    "ax.set_xlabel('Features', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('I-Gain')\n",
    "ax2.set_ylabel('Chi Squared')\n",
    "fig.legend(loc=\"upper right\", bbox_to_anchor=(1,1), bbox_transform=ax.transAxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "stats.spearmanr(chi2_score, i_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "Compare  \n",
    "- Baseline: all features\n",
    "- Top three, I-Gain and Chi-Square\n",
    "- Top six, I-Gain and Chi-Square\n",
    "- Top half (12), I-Gain and Chi-Square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=3)\n",
    "model = model.fit(X_train,y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "acc = accuracy_score(y_pred,y_test)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = X_train.shape[1]\n",
    "n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = [mutual_info_classif, chi2]\n",
    "k_options = [n_features, 3, 6, 10, 15]\n",
    "filt_scores = {}\n",
    "chi_scores = {}\n",
    "i_gain_scores = {}\n",
    "\n",
    "for the_filter in filters:\n",
    "    accs = []\n",
    "    for k_val in k_options:\n",
    "        FS_trans = SelectKBest(the_filter, \n",
    "                           k=k_val).fit(X_train, y_train)\n",
    "        X_tR_new = FS_trans.transform(X_train)\n",
    "        X_tS_new = FS_trans.transform(X_test)\n",
    "\n",
    "        model.fit(X_tR_new, y_train)\n",
    "\n",
    "        y_tS_pred = model.predict(X_tS_new)\n",
    "        \n",
    "        acc = accuracy_score(y_test, y_tS_pred)\n",
    "        accs.append(acc)\n",
    "        print(the_filter, k_val, acc)\n",
    "    filt_scores[the_filter.__name__] = accs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "%matplotlib inline \n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "width = 0.3\n",
    "sb = 'skyblue'\n",
    "\n",
    "options = ['All'] + k_options[1:]\n",
    "ig = filt_scores['mutual_info_classif']\n",
    "ch = filt_scores['chi2']\n",
    "\n",
    "y_pos = np.arange(len(options))\n",
    "\n",
    "p1 = ax.bar(y_pos-width, ig, width, align='center', \n",
    "            color=['red', 'blue', 'blue','blue','blue'],alpha=0.5)\n",
    "p2 = ax.bar(y_pos, ch, width, align='center', \n",
    "            color=['red', sb, sb, sb, sb],alpha=0.5)\n",
    "\n",
    "ax.legend((p1[1], p2[1]), ('I-Gain', 'Chi Squared'),loc='lower right')\n",
    "ax.set_ylim([0.5, 1])\n",
    "plt.grid(axis = 'y')\n",
    "plt.yticks(np.arange(0.5,1.05,0.1))\n",
    "\n",
    "plt.xticks(y_pos, options)\n",
    "plt.ylabel('Test Set Accuracy')\n",
    "plt.xlabel('Feature Counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid Filter Wrapper Strategy\n",
    "We rank the features using information gain (well mutual information) and select the _k_ best to build a classifier.  \n",
    "We iterate through increasing values of *k*.  \n",
    "`SelectKBest` is a _transform_ that transforms the training data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cv_acc_scores = []\n",
    "tst_acc_scores = []\n",
    "best_acc = 0\n",
    "best_k = 0\n",
    "for kk in range(1, X_train.shape[1]+1):\n",
    "    FS_trans = SelectKBest(mutual_info_classif, \n",
    "                           k=kk).fit(X_train, y_train)\n",
    "    X_tR_new = FS_trans.transform(X_train)\n",
    "    X_tS_new = FS_trans.transform(X_test)\n",
    "    cv_acc = cross_val_score(model, X_tR_new, y_train, cv=8)\n",
    "    cv_acc_scores.append(cv_acc.mean())\n",
    "    y_pred_temp = model.fit(X_tR_new, y_train).predict(X_tS_new)\n",
    "    tst_acc_scores.append(accuracy_score(y_pred_temp, y_test))\n",
    "    if cv_acc.mean() > best_acc:\n",
    "        best_acc = cv_acc.mean()\n",
    "        best_k = kk\n",
    "df['Training Acc.'] = cv_acc_scores\n",
    "df['Test Acc.'] = tst_acc_scores\n",
    "\n",
    "print(best_k, best_acc)\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "n = len(df.index)\n",
    "rr = range(0,n)\n",
    "fig, ax = plt.subplots()\n",
    "ax2 = ax.twinx()\n",
    "ax.bar(df.index, df[\"Mutual Info.\"], label='I-Gain',width=.35)\n",
    "\n",
    "ax2.plot(df.index, df[\"Training Acc.\"], color='green', label='Training Acc.')\n",
    "ax2.plot(df.index, df[\"Test Acc.\"], color='lightgreen', label='Test Acc')\n",
    "ax.set_xticks(rr)\n",
    "ax2.plot(best_k-1,best_acc,'gx') \n",
    "ax.set_xticklabels(list(df.index), rotation = 90)\n",
    "ax.set_xlabel('Features')\n",
    "ax.set_ylabel('I-Gain')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "fig.legend(loc=\"upper right\", bbox_to_anchor=(1,0.8), bbox_transform=ax.transAxes)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
