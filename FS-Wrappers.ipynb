{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection using Wrappers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "`scikit learn` does not provide a comprehenisive implementation of Wrapper feature selection so we use `MLxtend`.  \n",
    "http://rasbt.github.io/mlxtend/\n",
    "So you will probably need to install some libraries:  \n",
    "`pip install mlxtend`  \n",
    "`pip install joblib`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from matplotlib.ticker import MaxNLocator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Sequential Search on segmentation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_data = pd.read_csv('segmentation-all.csv')\n",
    "print(seg_data.shape)\n",
    "seg_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_data['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Prep \n",
    "- Extract the data from the dataframe into numpy arrays\n",
    "- Split into train and test sets \n",
    "- Apply a [0,1] Scaler. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = seg_data.pop('Class').values\n",
    "X_raw = seg_data.values\n",
    "X_tr_raw, X_ts_raw, y_train, y_test = train_test_split(X_raw, y, \n",
    "                                                       random_state=2, test_size=1/2)\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_tr_raw)\n",
    "X_test = scaler.transform(X_ts_raw)\n",
    "max_k = X_train.shape[1]\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline performance evaluation\n",
    "Using all features and *k*-NN:  \n",
    "- test performance on training data using cross validation,\n",
    "- test performance on test data using hold-out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kNN = KNeighborsClassifier(n_neighbors=4)\n",
    "kNN = kNN.fit(X_train,y_train)\n",
    "y_pred = kNN.predict(X_test)\n",
    "acc = accuracy_score(y_pred,y_test)\n",
    "cv_acc = cross_val_score(kNN, X_train, y_train, cv=8)\n",
    "\n",
    "print(\"X_Val on training all features: {0:.3f}\".format(cv_acc.mean())) \n",
    "print(\"Hold Out testing all features: {0:.3f}\".format(acc)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential Forward Selection\n",
    "Run SFS with k_features set to (1,max_k) - this will remember the best result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verb = 0\n",
    "sfs_forward = SFS(kNN, \n",
    "                  k_features= (1, max_k), \n",
    "                  forward=True, \n",
    "                  floating=False, \n",
    "                  verbose=verb,\n",
    "                  scoring='accuracy',\n",
    "                  cv=10, n_jobs = -1) # No. of threads depends on the machine.\n",
    "\n",
    "sfs_forward = sfs_forward.fit(X_train, y_train, \n",
    "                              custom_feature_names=seg_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The indexes and names of the features from the best perfroming subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfs_forward.k_feature_idx_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sfs_forward.k_feature_names_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig1 = plot_sfs(sfs_forward.get_metric_dict(), \n",
    "                ylabel='Training Accuracy',\n",
    "                kind='std_dev')\n",
    "\n",
    "plt.ylim([0.5, 1])\n",
    "plt.title('Sequential Forward Selection')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "print(sfs_forward.k_feature_names_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform the dataset using the selected subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sfs = sfs_forward.transform(X_train)\n",
    "X_test_sfs = sfs_forward.transform(X_test)\n",
    "\n",
    "kNN_sfs = kNN.fit(X_train_sfs,y_train)\n",
    "y_pred = kNN_sfs.predict(X_test_sfs)\n",
    "acc_SFS = accuracy_score(y_pred,y_test)\n",
    "cv_acc_SFS = cross_val_score(kNN, X_train_sfs, y_train, cv=8)\n",
    "\n",
    "print(\"X_train shape: \", X_train_sfs.shape)\n",
    "print(\"X_Val on SFS all features: {0:.3f}\".format(cv_acc_SFS.mean())) \n",
    "print(\"Hold Out testing: {0:2d} features selected using SFS: {1:.3f}\".format(len(sfs_forward.k_feature_idx_), acc_SFS)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backward Elimination\n",
    "If we set the SFS `forward` parameter to False it performs Backward Elimination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verb = 1\n",
    "sfs_backward = SFS(kNN, \n",
    "                  k_features=(1, max_k), \n",
    "                  forward=False, \n",
    "                  floating=False, \n",
    "                  verbose=verb,\n",
    "                  scoring='accuracy',\n",
    "                  cv=10, n_jobs = -1)\n",
    "\n",
    "sfs_backward = sfs_backward.fit(X_train, y_train, \n",
    "                              custom_feature_names=seg_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig1 = plot_sfs(sfs_backward.get_metric_dict(), \n",
    "                ylabel='Accuracy',\n",
    "                kind='std_dev')\n",
    "\n",
    "plt.ylim([0.5, 1])\n",
    "plt.title('Backward Elimination (w. StdDev)')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "print(sfs_backward.k_feature_names_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfs_backward.k_feature_idx_, len(sfs_backward.k_feature_idx_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_be = sfs_backward.transform(X_train)\n",
    "X_test_be = sfs_backward.transform(X_test)\n",
    "\n",
    "kNN_be = kNN.fit(X_train_be,y_train)\n",
    "y_pred = kNN_be.predict(X_test_be)\n",
    "acc_BE = accuracy_score(y_pred,y_test)\n",
    "cv_acc_BE = cross_val_score(kNN, X_train_be, y_train, cv=8)\n",
    "\n",
    "print(\"X_train shape: \", X_train_be.shape)\n",
    "print(\"X_Val on BE all features: {0:.3f}\".format(cv_acc_BE.mean())) \n",
    "print(\"Hold Out testing: {0:2d} features selected using BE: {1:.3f}\".format(len(sfs_backward.k_feature_idx_), acc_BE)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the overall results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "width = 0.2\n",
    "\n",
    "options = ['All', 'SFS', 'BE']\n",
    "n_feat = [X_train.shape[1], X_train_sfs.shape[1], X_train_be.shape[1]]\n",
    "accs = [acc,acc_SFS,acc_BE]\n",
    "xv = [cv_acc.mean(), cv_acc_SFS.mean(), cv_acc_BE.mean()]\n",
    "\n",
    "y_pos = np.arange(len(options))\n",
    "\n",
    "p1 = ax.bar(y_pos-width/2, xv, width, align='center', label = 'Train (X-val)',\n",
    "            color=['blue','blue','blue'],alpha=0.5)\n",
    "p2 = ax.bar(y_pos+width/2, accs , width, align='center', label = 'Test (Hold-out)',\n",
    "            color=['g','g','g'],alpha=0.5)\n",
    "\n",
    "ax.set_ylim([0.7, 1])\n",
    "ax2 = ax.twinx()\n",
    "\n",
    "p3 = ax2.plot([0,1,2],n_feat, color = 'red', label = 'Feature Count',\n",
    "              marker = 'x', ms = 10, linewidth=0)\n",
    "ax2.set_ylim([0, 20])\n",
    "\n",
    "ax.grid(axis = 'y')\n",
    "\n",
    "h1, l1 = ax.get_legend_handles_labels()\n",
    "h2, l2 = ax2.get_legend_handles_labels()\n",
    "ax2.legend(h1+h2, l1+l2, loc='lower right')\n",
    "\n",
    "ax2.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "plt.xticks(y_pos, options)\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax2.set_ylabel('Feature Count')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
